
\section{Mechanism Reduction}

As discussed, the first step to simplifying a complex task involves the partitioning data into categories. For a mechanism, we begin by looking at the reaction or species which are related to the area that is being researched. Items are partitioned into important, needed and redundant categories (described below). 

\begin{itemize}
    \item \textbf{Important} - reactions or species directly related to the topic / outcome we are interested in
    \item \textbf{Needed} - reactions/species required by the important species, such that they may perform their desired function
    \item \textbf{Redundant} - those we may remove with little or no consequence to the final outcome of the model. 
\end{itemize}



\subsection{Reaction Removal}
Since atmospheric chemical mechanism forms a numerically stiff system, a reduction in the number of reactions within a mechanism leads to a reduction in the computational burden experienced by a model each iteration forwards in time. Classically the identification of important reactions may be accomplished through the use or rate of production and loss analysis (SEC REF). This allows us to filter reactions contributing less than 5\% to the formation of any species we are interested in. Other methods using principal component analysis of the sensitivity of species (PCAS) also exist and are discussed in \cite{PCAS}.


\subsection{Species removal}
Similar to reaction removal, the removal of species is useful because the removing or combining of species inherently reduces or simplifies the reactions within a mechanism.  This method also has added benefit of reducing the size of the jacobian matrix used to propagate the chemical system forwards. For large systems which do not use a sparse framework, storing a $n^2$ matrix in memory can prove difficult.

Many methods of species reduction are possible. The simplest of these is through the use of trial and error\footnote{A tried and tested method for scientific discovery.} \citep{tur1990} (Method 1). Here the consuming reactions for a species are removed, and if the resulting deviation in results between the full and reduced mechanism is small, their results are kept. The main downside to this is that it only works on a per-species level, which may be very resource-consuming for large mechanisms.

With the use of sensitivity analysis, it is possible to remove species whose reaction are much slower than the rate-determining steps of a mechanism, \citep{frenk}. However, even after removing all slow-reacting species, those on a fast timescale remain. Here the use of Quasi-Steady-State Approximation (QSSA), \citep{QSSA}, can be used to identify species associated with fast timescale reactions. QSSA works on the assumption that such species have little to no change in concentration over time - i.e. the net flux ($\dot{v_i}$) is zero. Such an assumption causes an error $\Delta c_i$ of :
\begin{equation}
    \Delta c_i = \frac{\dot{v_i}}{J_{ii}}
\end{equation}  
where $J_{ii}$ is the diagonal of the Jacobian matrix. Here if the error for a species is small, the species may be removed from the mechanism. 


Finally, investigation of the system Jacobian can be used to identify redundant species, which is a `capable' and `efficient' method for removing most redundant reactions and species from the MCM, \citep{QSSA}. Use of a log-normalised Jacobian to determine which species can be removed is found in the connectivity method \cite{connectivity,cm}. 
Here the influence a 1\%  change in a species concentration has on the concentration of `important' species can be determined by

\begin{equation}
B_i  = \sum_j(({y_i}/{f_i})({\partial f_i}/{\partial y_i}))^2 \label{connectivity}
\end{equation}

 where $({y_i}/{f_i})({\partial f_i}/{\partial y_i})$ is element $i$ of the normalised Jacobian. Through an iterative process species with a low contribution to our important species can be found and removed.


\subsection{Lumping}

Rather than removing species or reactions from a mechanism we may combine them to form a new composite species. This is species lumping. To do this we must first consider how we determine species that are to be joined together, and then how their grouped reactions will contribute to every other species it reacts with. Some of the more general types of lumping styles are outlined below. 


\subsubsection{Chemical Lumping}\label{sec:chemlump}
Mechanisms follow protocols in their generation. This produces reaction styles that many like-structured species follow in their degradation. In determining such classes we may be able to generalise like-species reactions and group them as one.
An example of this is the Common Representative Intermediates (CRI) Mechanism (described in \autoref{whycri}).  Here the ozone production potential of the species within the MCM is used to simplify and reduce it. Species with a similar \ch{c-C} and \ch{c-H} ratio (their CRI index) are lumped into a single representative species. Alternatively, time scale analysis for species lumping has been successfully applied by  \cite{lifetime}. Here it is seen that many groups of species have coefficients that are identical or sufficiently similar, resulting based on their type. This results in a similar overall lifetime for species in the same group, allowing them to be lumped together with little overall consequence to the final result of the simulation. 

